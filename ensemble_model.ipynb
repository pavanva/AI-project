{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forcing single GPU\n",
      "Left next 1 GPU(s) unmasked: [3] (from [3 2] available)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jr/anaconda3/envs/bap/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import tf_utils\n",
    "\n",
    "from tensorflow_addons.metrics import CohenKappa\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, BatchNormalization, Activation, concatenate, GlobalAveragePooling2D, Dense, ZeroPadding2D, AveragePooling2D\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import Nadam, SGD\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from padding_generator import generator1, generator2\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data = load_data_from_csv(SetType.TRAIN)\n",
    "data['Y'] = data['label'].apply(lambda x: 1 if x == 'True' else 0)\n",
    "\n",
    "val_data = load_data_from_csv(SetType.VALID)\n",
    "val_data['Y'] = val_data['label'].apply(lambda x: 1 if x == 'True' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Found 36256 validated image filenames belonging to 2 classes.\n",
      "Found 36256 validated image filenames belonging to 2 classes.\n",
      "Predicting validation data...\n",
      "Found 3197 validated image filenames belonging to 2 classes.\n",
      "Found 29 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#select models\n",
    "selected_models = ['resnet_34', 'resnet_101', 'densenet']\n",
    "\n",
    "#load models\n",
    "models = [load_model(data_paths(m)['best'], compile=False) for m in selected_models]\n",
    "\n",
    "model_count = len(selected_models)\n",
    "for model, name in zip(models, selected_models):\n",
    "    assert model.input.shape.as_list() == models[0].input.shape.as_list()\n",
    "    \n",
    "    #keras requires unique names\n",
    "    model._name = name\n",
    "        \n",
    "input_size = model.input.shape.as_list()[1]\n",
    "\n",
    "# create a model with n outputs\n",
    "inp = Input((input_size, input_size, 1))\n",
    "out = concatenate( [ model(inp) for model in models ] )\n",
    "model_ens = Model(inputs=inp, outputs=out, name='Ensemble')\n",
    "\n",
    "#predict data\n",
    "print('Predicting...')\n",
    "#this might take a while\n",
    "pred = predict_all(model_ens, SetType.TRAIN, generator=generator2)\n",
    "print('Predicting validation data...')\n",
    "val_pred = predict_all(model_ens, SetType.VALID, generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "270/284 [===========================>..] - ETA: 0s - loss: 0.3758 - cohen_kappa: 0.6991\n",
      "Epoch 00001: val_cohen_kappa improved from -inf to 0.61281, saving model to ../models/tmp_best_perc.h5\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.3732 - cohen_kappa: 0.6999 - val_loss: 0.4568 - val_cohen_kappa: 0.6128\n",
      "Epoch 2/5\n",
      "273/284 [===========================>..] - ETA: 0s - loss: 0.3105 - cohen_kappa: 0.7265\n",
      "Epoch 00002: val_cohen_kappa did not improve from 0.61281\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 0.3107 - cohen_kappa: 0.7267 - val_loss: 0.4687 - val_cohen_kappa: 0.6031\n",
      "Epoch 3/5\n",
      "272/284 [===========================>..] - ETA: 0s - loss: 0.3085 - cohen_kappa: 0.7283\n",
      "Epoch 00003: val_cohen_kappa did not improve from 0.61281\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 0.3092 - cohen_kappa: 0.7279 - val_loss: 0.4859 - val_cohen_kappa: 0.5996\n",
      "Epoch 4/5\n",
      "273/284 [===========================>..] - ETA: 0s - loss: 0.3093 - cohen_kappa: 0.7284\n",
      "Epoch 00004: val_cohen_kappa did not improve from 0.61281\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 0.3087 - cohen_kappa: 0.7284 - val_loss: 0.4811 - val_cohen_kappa: 0.6021\n",
      "Epoch 5/5\n",
      "282/284 [============================>.] - ETA: 0s - loss: 0.3084 - cohen_kappa: 0.7297\n",
      "Epoch 00005: val_cohen_kappa did not improve from 0.61281\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 0.3083 - cohen_kappa: 0.7299 - val_loss: 0.4758 - val_cohen_kappa: 0.6001\n"
     ]
    }
   ],
   "source": [
    "#create model for stacking ensemble\n",
    "inp_per = Input(len(models))\n",
    "x = Dense(25, activation='relu')(inp_per)\n",
    "x = Dense(25, activation='relu')(x)\n",
    "out_per = Dense(1, activation='sigmoid', name = 'out')(x)\n",
    "\n",
    "#checkpoint best\n",
    "tmp_file_name = os.path.join(MODEL_FOLDER, 'tmp_best_perc.h5')\n",
    "check = ModelCheckpoint(tmp_file_name, monitor='val_cohen_kappa', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "#create and fit model\n",
    "p = Model(inputs=inp_per, outputs=out_per)\n",
    "p.compile(SGD(0.1), loss='binary_crossentropy', metrics = CohenKappa(num_classes=2))\n",
    "p.fit(pred, data['Y'].to_numpy(), validation_data = (val_pred, val_data['Y'].to_numpy()), epochs = 5, callbacks = [ check ], batch_size = 128)\n",
    "\n",
    "#load best model\n",
    "p = load_model(tmp_file_name)\n",
    "os.remove(tmp_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unite and save\n",
    "PATHS = data_paths('ensemble')\n",
    "\n",
    "inp = Input((input_size, input_size, 1))\n",
    "\n",
    "x = model_ens(inp)\n",
    "\n",
    "model = Model(inputs=inp, outputs=p(x))\n",
    "model.save(PATHS['best'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
